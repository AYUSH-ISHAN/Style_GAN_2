{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Style_GAN_2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d97vEQ-cB1er"
      },
      "source": [
        "######   Will directly load CIFAR-10 dataset from Kaggle in the colab notebook.\n",
        "######   as did in semantics segementation part .\n",
        "\n",
        "\n",
        "# ! pip install kaggle\n",
        "# ! mkdir ~/.kaggle\n",
        "# ! cp kaggle.json ~/.kaggle/\n",
        "# ! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# ! kaggle datasets download wordroid/cifar10-object-recognition-in-images-zip-file \n",
        "\n",
        "# ! unzip cifar10-object-recognition-in-images-zip-file.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUDH0CQtm1v3",
        "outputId": "e24dea01-5311-45b0-ae4b-11683a4ae3c1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  6 04:53:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBYmTh8HkgaY",
        "outputId": "4dfa986f-0a92-4a4f-a5ad-8faa30afc156"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHj4M-APkgtM",
        "outputId": "10371df3-67ea-42ed-f99c-8e0240cd391e"
      },
      "source": [
        "# Setting the destination in file and installing the required version of torch and torch vision.\n",
        "\n",
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/colab-sg2-ada-pytorch\"):\n",
        "    %cd \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n",
        "\n",
        "!pip install ninja opensimplex torch==1.7.1 torchvision==0.8.2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting opensimplex\n",
            "  Downloading opensimplex-0.3-py3-none-any.whl (15 kB)\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 23 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, opensimplex, ninja\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed ninja-1.10.2 opensimplex-0.3 torch-1.7.1 torchvision-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgm-WerKMQg6",
        "outputId": "4c3a28e6-805e-41b6-f317-f518f2bee58e"
      },
      "source": [
        "# to convert the downloaded cifar-10 file to zip file, so that it can be feed to model.\n",
        "\n",
        "!python dataset_tool.py --source=./downloads/cifar-10-python.tar.gz --dest=./datasets/cifar10.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 50000/50000 [00:47<00:00, 1056.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUpwp2KgNd4d",
        "outputId": "7a6a781b-87e2-4251-b2e4-c1b00504d041"
      },
      "source": [
        "# loading the pretrained weights manually and generating some seed images \n",
        "\n",
        "!python generate.py --outdir=out --seeds=0-35 --class=1 \\\n",
        "    --network='./pretrained/cifar10.pkl'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/cifar10.pkl\"...\n",
            "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/cifar10.pkl ... done\n",
            "Generating image for seed 0 (0/36) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Generating image for seed 1 (1/36) ...\n",
            "Generating image for seed 2 (2/36) ...\n",
            "Generating image for seed 3 (3/36) ...\n",
            "Generating image for seed 4 (4/36) ...\n",
            "Generating image for seed 5 (5/36) ...\n",
            "Generating image for seed 6 (6/36) ...\n",
            "Generating image for seed 7 (7/36) ...\n",
            "Generating image for seed 8 (8/36) ...\n",
            "Generating image for seed 9 (9/36) ...\n",
            "Generating image for seed 10 (10/36) ...\n",
            "Generating image for seed 11 (11/36) ...\n",
            "Generating image for seed 12 (12/36) ...\n",
            "Generating image for seed 13 (13/36) ...\n",
            "Generating image for seed 14 (14/36) ...\n",
            "Generating image for seed 15 (15/36) ...\n",
            "Generating image for seed 16 (16/36) ...\n",
            "Generating image for seed 17 (17/36) ...\n",
            "Generating image for seed 18 (18/36) ...\n",
            "Generating image for seed 19 (19/36) ...\n",
            "Generating image for seed 20 (20/36) ...\n",
            "Generating image for seed 21 (21/36) ...\n",
            "Generating image for seed 22 (22/36) ...\n",
            "Generating image for seed 23 (23/36) ...\n",
            "Generating image for seed 24 (24/36) ...\n",
            "Generating image for seed 25 (25/36) ...\n",
            "Generating image for seed 26 (26/36) ...\n",
            "Generating image for seed 27 (27/36) ...\n",
            "Generating image for seed 28 (28/36) ...\n",
            "Generating image for seed 29 (29/36) ...\n",
            "Generating image for seed 30 (30/36) ...\n",
            "Generating image for seed 31 (31/36) ...\n",
            "Generating image for seed 32 (32/36) ...\n",
            "Generating image for seed 33 (33/36) ...\n",
            "Generating image for seed 34 (34/36) ...\n",
            "Generating image for seed 35 (35/36) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxJb_fkRkgvy"
      },
      "source": [
        "## Setting up some Global Parameters\n",
        "\n",
        "#required: definitely edit these!\n",
        "dataset_path = './datasets/cifar10.zip'\n",
        "resume_from = './pretrained/wikiart.pkl'\n",
        "aug_strength = 0.0\n",
        "train_count = 0\n",
        "mirror_x = True\n",
        "#mirror_y = False\n",
        "\n",
        "#optional: you might not need to edit these\n",
        "gamma_value = 50.0\n",
        "augs = 'bg'\n",
        "config = '11gb-gpu'  # 'cifar'\n",
        "snapshot_count = 4"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT_GnQqykgy2",
        "outputId": "193e4c1b-2ff6-4566-a11d-d1e61afd4593"
      },
      "source": [
        "## Giving command to train..\n",
        "\n",
        "!python train.py --gpus=1 --cfg=$config --metrics=None --outdir=./results --data=$dataset_path --snap=$snapshot_count --resume=$resume_from --augpipe=$augs --initstrength=$aug_strength --gamma=$gamma_value --mirror=$mirror_x --mirrory=False --nkimg=$train_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 4,\n",
            "  \"network_snapshot_ticks\": 4,\n",
            "  \"metrics\": [],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./datasets/cifar10.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 50000,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 32\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 32768,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.002,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.002,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 50.0\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"ema_kimg\": 10,\n",
            "  \"ema_rampup\": null,\n",
            "  \"nimg\": 0,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_p\": 0.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"./pretrained/wikiart.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"./results/00006-cifar10-mirror-11gb-gpu-gamma50-bg-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   ./results/00006-cifar10-mirror-11gb-gpu-gamma50-bg-resumecustom\n",
            "Training data:      ./datasets/cifar10.zip\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   50000\n",
            "Image resolution:   32\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  100000\n",
            "Image shape: [3, 32, 32]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "starting G epochs:  0.0\n",
            "Resuming from \"./pretrained/wikiart.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator            Parameters  Buffers  Output shape      Datatype\n",
            "---                  ---         ---      ---               ---     \n",
            "mapping.fc0          262656      -        [4, 512]          float32 \n",
            "mapping.fc1          262656      -        [4, 512]          float32 \n",
            "mapping.fc2          262656      -        [4, 512]          float32 \n",
            "mapping.fc3          262656      -        [4, 512]          float32 \n",
            "mapping.fc4          262656      -        [4, 512]          float32 \n",
            "mapping.fc5          262656      -        [4, 512]          float32 \n",
            "mapping.fc6          262656      -        [4, 512]          float32 \n",
            "mapping.fc7          262656      -        [4, 512]          float32 \n",
            "mapping              -           512      [4, 8, 512]       float32 \n",
            "synthesis.b4.conv1   2622465     32       [4, 512, 4, 4]    float32 \n",
            "synthesis.b4.torgb   264195      -        [4, 3, 4, 4]      float32 \n",
            "synthesis.b4:0       8192        16       [4, 512, 4, 4]    float32 \n",
            "synthesis.b4:1       -           -        [4, 512, 4, 4]    float32 \n",
            "synthesis.b8.conv0   2622465     80       [4, 512, 8, 8]    float16 \n",
            "synthesis.b8.conv1   2622465     80       [4, 512, 8, 8]    float16 \n",
            "synthesis.b8.torgb   264195      -        [4, 3, 8, 8]      float16 \n",
            "synthesis.b8:0       -           16       [4, 512, 8, 8]    float16 \n",
            "synthesis.b8:1       -           -        [4, 512, 8, 8]    float32 \n",
            "synthesis.b16.conv0  2622465     272      [4, 512, 16, 16]  float16 \n",
            "synthesis.b16.conv1  2622465     272      [4, 512, 16, 16]  float16 \n",
            "synthesis.b16.torgb  264195      -        [4, 3, 16, 16]    float16 \n",
            "synthesis.b16:0      -           16       [4, 512, 16, 16]  float16 \n",
            "synthesis.b16:1      -           -        [4, 512, 16, 16]  float32 \n",
            "synthesis.b32.conv0  2622465     1040     [4, 512, 32, 32]  float16 \n",
            "synthesis.b32.conv1  2622465     1040     [4, 512, 32, 32]  float16 \n",
            "synthesis.b32.torgb  264195      -        [4, 3, 32, 32]    float16 \n",
            "synthesis.b32:0      -           16       [4, 512, 32, 32]  float16 \n",
            "synthesis.b32:1      -           -        [4, 512, 32, 32]  float32 \n",
            "---                  ---         ---      ---               ---     \n",
            "Total                21523475    3392     -                 -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape      Datatype\n",
            "---            ---         ---      ---               ---     \n",
            "b32.fromrgb    2048        16       [4, 512, 32, 32]  float16 \n",
            "b32.skip       262144      16       [4, 512, 16, 16]  float16 \n",
            "b32.conv0      2359808     16       [4, 512, 32, 32]  float16 \n",
            "b32.conv1      2359808     16       [4, 512, 16, 16]  float16 \n",
            "b32            -           16       [4, 512, 16, 16]  float16 \n",
            "b16.skip       262144      16       [4, 512, 8, 8]    float16 \n",
            "b16.conv0      2359808     16       [4, 512, 16, 16]  float16 \n",
            "b16.conv1      2359808     16       [4, 512, 8, 8]    float16 \n",
            "b16            -           16       [4, 512, 8, 8]    float16 \n",
            "b8.skip        262144      16       [4, 512, 4, 4]    float16 \n",
            "b8.conv0       2359808     16       [4, 512, 8, 8]    float16 \n",
            "b8.conv1       2359808     16       [4, 512, 4, 4]    float16 \n",
            "b8             -           16       [4, 512, 4, 4]    float16 \n",
            "b4.mbstd       -           -        [4, 513, 4, 4]    float32 \n",
            "b4.conv        2364416     16       [4, 512, 4, 4]    float32 \n",
            "b4.fc          4194816     -        [4, 512]          float32 \n",
            "b4.out         513         -        [4, 1]            float32 \n",
            "---            ---         ---      ---               ---     \n",
            "Total          21507073    224      -                 -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 1m 03s       sec/tick 11.6    sec/kimg 2908.34 maintenance 51.6   cpumem 2.59   gpumem 9.14   augment 0.000\n",
            "tick 1     kimg 4.0      time 8m 49s       sec/tick 453.6   sec/kimg 113.39  maintenance 12.1   cpumem 2.97   gpumem 1.32   augment 0.000\n",
            "tick 2     kimg 8.0      time 16m 22s      sec/tick 453.1   sec/kimg 113.27  maintenance 0.1    cpumem 2.97   gpumem 1.32   augment 0.000\n",
            "tick 3     kimg 12.0     time 23m 55s      sec/tick 453.1   sec/kimg 113.28  maintenance 0.1    cpumem 2.97   gpumem 1.32   augment 0.000\n",
            "tick 4     kimg 16.0     time 31m 28s      sec/tick 453.0   sec/kimg 113.24  maintenance 0.1    cpumem 2.97   gpumem 1.32   augment 0.000\n",
            "tick 5     kimg 20.0     time 39m 13s      sec/tick 452.6   sec/kimg 113.16  maintenance 12.0   cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 6     kimg 24.0     time 46m 46s      sec/tick 452.7   sec/kimg 113.18  maintenance 0.1    cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 7     kimg 28.0     time 54m 18s      sec/tick 452.5   sec/kimg 113.13  maintenance 0.1    cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 8     kimg 32.0     time 1h 01m 51s   sec/tick 452.6   sec/kimg 113.16  maintenance 0.1    cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 9     kimg 36.0     time 1h 09m 36s   sec/tick 453.0   sec/kimg 113.24  maintenance 12.0   cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 10    kimg 40.0     time 1h 17m 09s   sec/tick 452.9   sec/kimg 113.22  maintenance 0.1    cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 11    kimg 44.0     time 1h 24m 42s   sec/tick 453.0   sec/kimg 113.24  maintenance 0.1    cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 12    kimg 48.0     time 1h 32m 15s   sec/tick 453.2   sec/kimg 113.29  maintenance 0.1    cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 13    kimg 52.0     time 1h 40m 00s   sec/tick 453.0   sec/kimg 113.24  maintenance 11.9   cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 14    kimg 56.0     time 1h 47m 33s   sec/tick 452.6   sec/kimg 113.15  maintenance 0.1    cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 15    kimg 60.0     time 1h 55m 05s   sec/tick 452.3   sec/kimg 113.07  maintenance 0.1    cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 16    kimg 64.0     time 2h 02m 38s   sec/tick 452.6   sec/kimg 113.16  maintenance 0.1    cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 17    kimg 68.0     time 2h 10m 22s   sec/tick 452.5   sec/kimg 113.13  maintenance 11.8   cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 18    kimg 72.0     time 2h 17m 55s   sec/tick 452.6   sec/kimg 113.14  maintenance 0.1    cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 19    kimg 76.0     time 2h 25m 27s   sec/tick 452.3   sec/kimg 113.08  maintenance 0.1    cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 20    kimg 80.0     time 2h 33m 00s   sec/tick 452.5   sec/kimg 113.14  maintenance 0.1    cpumem 2.99   gpumem 1.32   augment 0.000\n",
            "tick 21    kimg 84.0     time 2h 40m 45s   sec/tick 453.0   sec/kimg 113.25  maintenance 12.0   cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 22    kimg 88.0     time 2h 48m 18s   sec/tick 453.0   sec/kimg 113.24  maintenance 0.1    cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 23    kimg 92.0     time 2h 55m 50s   sec/tick 452.7   sec/kimg 113.16  maintenance 0.1    cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 24    kimg 96.0     time 3h 03m 23s   sec/tick 453.1   sec/kimg 113.27  maintenance 0.1    cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 25    kimg 100.0    time 3h 11m 08s   sec/tick 452.7   sec/kimg 113.18  maintenance 11.9   cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 26    kimg 104.0    time 3h 18m 41s   sec/tick 452.7   sec/kimg 113.18  maintenance 0.1    cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 27    kimg 108.0    time 3h 26m 14s   sec/tick 452.7   sec/kimg 113.16  maintenance 0.1    cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 28    kimg 112.0    time 3h 33m 46s   sec/tick 452.7   sec/kimg 113.16  maintenance 0.1    cpumem 2.98   gpumem 1.32   augment 0.000\n",
            "tick 29    kimg 116.0    time 3h 41m 31s   sec/tick 452.3   sec/kimg 113.08  maintenance 11.9   cpumem 2.98   gpumem 1.32   augment 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrOyB-cKk7Wx"
      },
      "source": [
        "!python generate.py --outdir=/content/out/images/ --trunc=0.7 --size=1820-1024 --scale-type=symm --seeds=0-499 --network=/content/crystal.pkl"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CNIjiD_k7aQ"
      },
      "source": [
        "!python generate.py --process=\"truncation\" --outdir=/content/out/trunc-trav-3/ --start=-0.8 --stop=2.8 --increment=0.02 --seeds=470 --network=/content/drive/MyDrive/stylegan2-transfer-models/mixed6k-network-snapshot-016470.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjEjPiXQk7dR"
      },
      "source": [
        "!python generate.py --outdir=/content/out/video1-w-0.5/ --space=\"z\" --trunc=0.5 --process=\"interpolation\" --seeds=463,470 --network=/content/drive/MyDrive/stylegan2-transfer-models/mixed6k-network-snapshot-016470.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtaxw13Ok7ff"
      },
      "source": [
        "!python generate.py --outdir=out/video1-w/ --space=\"w\" --trunc=1 --process=\"interpolation\" --seeds=85,265,297,849 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKndl2uKkg4O"
      },
      "source": [
        "!python generate.py --outdir=out/slerp-z/ --space=\"z\" --trunc=1 --process=\"interpolation\" --interpolation=\"slerp\" --seeds=85,265,297,849 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl --frames=24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCNMGGrOHIpa"
      },
      "source": [
        "!python generate.py --outdir=out/slerp-w/ --space=\"w\" --trunc=1 --process=\"interpolation\" --interpolation=\"slerp\" --seeds=85,265,297,849 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl --frames=12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emfhdifIHIr5"
      },
      "source": [
        "!python generate.py --outdir=out/video-noiseloop-0.9d/ --trunc=0.8 --process=\"interpolation\" --interpolation=\"noiseloop\" --diameter=0.9 --random_seed=100 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbgp_33QHIvE"
      },
      "source": [
        "!python generate.py --outdir=out/video-circularloop/ --trunc=1 --process=\"interpolation\" --interpolation=\"circularloop\" --diameter=800.00 --frames=720 --random_seed=90 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ0PcYPOHIx2"
      },
      "source": [
        "!python projector.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQSAu5NWHPLG"
      },
      "source": [
        "!python projector.py --network=/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/results/00023-chin-morris-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000304.pkl --outdir=/content/projector/ --target=/content/img005421_0.png --num-steps=200 --seed=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOhMK-ZmHPOj"
      },
      "source": [
        "!python /content/stylegan2-ada-pytorch/pbaylies_projector.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4tIVtL1HWky"
      },
      "source": [
        "!python /content/stylegan2-ada-pytorch/pbaylies_projector.py --network=/content/ladiesblack.pkl --outdir=/content/projector-no-clip-006265-4-inv-3k/ --target-image=/content/img006265-4-inv.png --num-steps=3000 --use-clip=False --use-center=False --seed=99"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoOCtsN5HWnn"
      },
      "source": [
        "!python combine_npz.py --outdir=/content/npz --npzs='/content/projector-no-clip-006264-1-inv-3k/projector-no-clip-006264-1-inv-3k.npz,/content/projector-no-clip-006265-1-inv-3k/projector-no-clip-006265-1-inv-3k.npz,/content/projector-no-clip-006264-5-inv-3k/projector-no-clip-006264-5-inv-3k.npz,/content/projector-no-clip-006265-3-inv-3k/projector-no-clip-006265-3-inv-3k.npz,/content/projector-no-clip-006265-4-inv-3k/projector-no-clip-006265-4-inv-3k.npz,/content/projector-no-clip-006264-1-inv-3k/projector-no-clip-006264-1-inv-3k.npz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiNCz204HWq0"
      },
      "source": [
        "!python generate.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UntCd4i5Hgbi"
      },
      "source": [
        "!python generate.py --process=interpolation --interpolation=linear --easing=easeInOutQuad --space=w --network=/content/ladiesblack.pkl --outdir=/content/combined-proj/ --projected-w=/content/npz/combined.npz --frames=120"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLNpOzOYHgex"
      },
      "source": [
        "!python closed_form_factorization.py --out=/content/ladiesblack-cff.pt --ckpt=/content/ladiesblack.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT562ZOdHgjH"
      },
      "source": [
        "!python apply_factor.py -i 0 -d 10 --seeds 5,10 --ckpt /content/ladiesblack.pkl /content/ladiesblack-cff.pt --output /content/cff-vid/ --video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TKHJ__yHmu8"
      },
      "source": [
        "for i in range(512):\n",
        "  !python apply_factor.py -i {i} -d 10 --seeds 177 --ckpt /content/drive/MyDrive/network-snapshot-008720.pkl /content/ladies-black-cff.pt --output /content/drive/MyDrive/ladiesblack-cff-17/ --video #--out_prefix 'ladiesblack-factor-{i}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0PoBrcSHmxj"
      },
      "source": [
        "!python flesh_digression.py --pkl /content/stylegan2-ada-pytorch/pretrained/wikiart.pkl --psi 0.5 --seed 9999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41WezPPHHm10"
      },
      "source": [
        "!python blend_models.py --lower_res_pkl /content/ffhq-pt.pkl --split_res 64 --higher_res_pkl /content/bone-bone-pt.pkl --output_path /content/ffhq-bonebone-split64.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztC-nYJ2Hglb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}